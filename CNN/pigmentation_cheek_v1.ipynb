{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 볼 색소침착\n",
        "Best hyperparameters:\n",
        "\n",
        "{'learning_rate': 3.0207059901269228e-05, 'batch_size': 64, 'weight_decay': 5.758813276927239e-05, 'model': 'ResNetforClassification2', 'dropout': 0.4085688567343784, 'hidden_dim': 106}"
      ],
      "metadata": {
        "id": "JCoIYF4PSARq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model_save_path =  '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/지우님/orientation/orientation_pigmentation_cheek/model/model_v1/pigmentation_cheek_v2.pth'"
      ],
      "metadata": {
        "id": "WFd6wg8Wpths"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKFa9qAS6dy9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNlPX4dE7HD2",
        "outputId": "8640abfb-608a-4b88-ed03-0ba4b0245185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dropout_rate = 0.4085688567343784\n",
        "hidden_dim = 106\n",
        "weight_decay = 5.758813276927239e-05\n",
        "lr = 3.0207059901269228e-05\n",
        "batch_size = 64\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from torchvision.models import ResNet50_Weights\n"
      ],
      "metadata": {
        "id": "_eHg3WacUtc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from torchvision.models import ResNet50_Weights\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class SkinDataset(Dataset):\n",
        "    def __init__(self, csv_file=None, image_folder=None, image_paths=None, labels=None, transform=None):\n",
        "        if csv_file is not None and image_folder is not None:\n",
        "            # CSV 파일 로드 및 레이블 설정\n",
        "            self.image_paths = []\n",
        "            self.labels = []\n",
        "            self.transform = transform\n",
        "\n",
        "            df = pd.read_csv(csv_file)\n",
        "\n",
        "                # os.walk()를 사용하여 모든 하위 디렉토리와 파일 탐색\n",
        "            for root, dirs, files in os.walk(image_folder):\n",
        "                for dir_name in dirs:\n",
        "                    l_r_folder_path = os.path.join(root, dir_name)\n",
        "                    for root, dirs, files in os.walk(l_r_folder_path):\n",
        "                        for image_file in files:\n",
        "                            if image_file.endswith(('.jpg')):  # 다른 파일 형식도 포함\n",
        "                                image_path = os.path.join(root, image_file)\n",
        "                                image_id = image_file.split('_')[0]\n",
        "\n",
        "\n",
        "                                if \"r_cheek\" in root:\n",
        "                                    label_data = df[df['ID'] == int(image_id)]['r_cheek_pigmentation'].values\n",
        "                                elif \"l_cheek\" in root:\n",
        "                                    label_data = df[df['ID'] == int(image_id)]['l_cheek_pigmentation'].values\n",
        "                                else:\n",
        "                                    continue\n",
        "\n",
        "                                if len(label_data) > 0:\n",
        "                                    label = label_data[0]\n",
        "                                    self.image_paths.append(image_path)\n",
        "                                    self.labels.append(label)\n",
        "\n",
        "                # 넘파이 배열로 변경\n",
        "                self.image_paths = np.array(self.image_paths)\n",
        "                self.labels = np.array(self.labels)\n",
        "\n",
        "                # 데이터가 비어있지 않은지 확인\n",
        "                if len(self.image_paths) == 0:\n",
        "                    raise ValueError(\"이미지 없음\")\n",
        "\n",
        "        elif image_paths is not None and labels is not None:\n",
        "            self.image_paths = np.array(image_paths)\n",
        "            self.labels = np.array(labels)\n",
        "            self.transform = transform\n",
        "        else:\n",
        "            raise ValueError(\"Either (csv_file and image_folder) or (image_paths and labels) must be provided\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('YCbCr')  # YCbCr 색상 공간으로 변환\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "\n",
        "# 데이터셋 준비\n",
        "csv_file = '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/data/annotation/annotation_class2.csv'\n",
        "image_folder = '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/data/image/Orientation/train/cheek'\n",
        "\n",
        "\n",
        "# 데이터 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # ResNet50의 입력 크기에 맞게 조정\n",
        "    transforms.ToTensor(),  # 텐서로 변환\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 정규화\n",
        "])\n",
        "\n",
        "# 전체 데이터셋 생성\n",
        "full_dataset = SkinDataset(csv_file=csv_file, image_folder=image_folder, transform=transform)\n",
        "\n",
        "# 데이터 분할\n",
        "image_paths = full_dataset.image_paths\n",
        "labels = full_dataset.labels\n",
        "train_image_paths, val_image_paths, train_labels, val_labels = train_test_split(image_paths, labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# 데이터셋 생성\n",
        "train_dataset = SkinDataset(image_paths=train_image_paths, labels=train_labels, transform=transform)\n",
        "val_dataset = SkinDataset(image_paths=val_image_paths, labels=val_labels, transform=transform)\n",
        "\n",
        "# DataLoader 생성\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=3)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=3)\n",
        "\n",
        "# 모델 정의\n",
        "class ResNetforClassification(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_rate= dropout_rate, hidden_dim=hidden_dim):\n",
        "        super(ResNetforClassification, self).__init__()\n",
        "        # Pretrained ResNet50 모델 로드\n",
        "        self.resnet50 = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "        # ResNet50의 마지막 fc 레이어의 입력 차원 자동으로 가져오기\n",
        "        num_ftrs = self.resnet50.fc.in_features\n",
        "        self.resnet50.fc = nn.Identity()  # Remove the classification head\n",
        "\n",
        "        self.fc1 = nn.Linear(num_ftrs, hidden_dim)  # 중간 차원으로 64 선택 (언제나 바꿀 수 있음)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)  # 최종 출력 차원은 클래스 수\n",
        "\n",
        "    def forward(self, image):\n",
        "        image_features = self.resnet50(image) # ResNet50을 통해 이미지 특징 추출\n",
        "        x = self.fc1(image_features)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)  # 드롭아웃 적용\n",
        "        x = self.fc2(x) # 최종 FC 레이어\n",
        "        return x\n",
        "\n",
        "\n",
        "# `device` 변수를 여기에 선언\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 클래스 가중치 정의\n",
        "class_weights = torch.tensor([0.9138, 0.4061], dtype=torch.float32).to(device)\n",
        "\n",
        "num_classes = 2  # 색소침착 등급이 2개\n",
        "model = ResNetforClassification(num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)  # 클래스 가중치 추가\n",
        "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=20, eta_min=1e-6)\n",
        "\n",
        "\n",
        "# 조기 종료 클래스\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "\n",
        "# 모델 학습 및 검증\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50, patience=5):\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        corrects = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device).long()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            corrects += torch.sum(preds == labels.data)\n",
        "            total += labels.size(0)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = corrects.double() / total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        val_corrects = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device).long()\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_corrects += torch.sum(preds == labels.data)\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        val_loss = val_running_loss / len(val_loader.dataset)\n",
        "        val_acc = val_corrects.double() / val_total\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_acc:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}')\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model, model_save_path)\n",
        "\n",
        "        early_stopping(val_loss)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "model_save_path = '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/지우님/orientation/orientation_pigmentation_cheek/model/model_v1/pigmentation_cheek_v1.pth'\n",
        "\n",
        "\n",
        "model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50, patience=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD40S1Nn8diD",
        "outputId": "0fb9deb3-4ae9-4028-e465-d4442f769095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Loss: 0.6589, Train Accuracy: 0.6112, Val Loss: 0.6067, Val Accuracy: 0.6684\n",
            "Epoch [2/50], Train Loss: 0.4950, Train Accuracy: 0.7987, Val Loss: 0.4011, Val Accuracy: 0.8481\n",
            "Epoch [3/50], Train Loss: 0.2974, Train Accuracy: 0.8853, Val Loss: 0.2994, Val Accuracy: 0.8684\n",
            "Epoch [4/50], Train Loss: 0.1626, Train Accuracy: 0.9473, Val Loss: 0.2490, Val Accuracy: 0.9063\n",
            "Epoch [5/50], Train Loss: 0.0883, Train Accuracy: 0.9721, Val Loss: 0.2304, Val Accuracy: 0.9241\n",
            "Epoch [6/50], Train Loss: 0.0477, Train Accuracy: 0.9884, Val Loss: 0.2312, Val Accuracy: 0.9367\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch [7/50], Train Loss: 0.0289, Train Accuracy: 0.9927, Val Loss: 0.2339, Val Accuracy: 0.9266\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch [8/50], Train Loss: 0.0239, Train Accuracy: 0.9958, Val Loss: 0.2674, Val Accuracy: 0.9291\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch [9/50], Train Loss: 0.0163, Train Accuracy: 0.9977, Val Loss: 0.2160, Val Accuracy: 0.9342\n",
            "Epoch [10/50], Train Loss: 0.0101, Train Accuracy: 0.9986, Val Loss: 0.2493, Val Accuracy: 0.9342\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch [11/50], Train Loss: 0.0087, Train Accuracy: 0.9989, Val Loss: 0.2496, Val Accuracy: 0.9266\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch [12/50], Train Loss: 0.0073, Train Accuracy: 0.9992, Val Loss: 0.2834, Val Accuracy: 0.9190\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch [13/50], Train Loss: 0.0075, Train Accuracy: 0.9980, Val Loss: 0.2371, Val Accuracy: 0.9392\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch [14/50], Train Loss: 0.0064, Train Accuracy: 0.9992, Val Loss: 0.2449, Val Accuracy: 0.9367\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZmzZvc5Ni4bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0V_rPPTi4ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IhmVm2yv7fSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from torchvision.models import ResNet50_Weights\n",
        "\n",
        "#데이터 셋 클래스 정의 (오른쪽눈가, 왼쪽눈가 구분)\n",
        "class SkinDataset(Dataset):\n",
        "    def __init__(self, csv_file, r_cheek_folder, l_cheek_folder, transform=None):\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "\n",
        "        #csv파일 로드\n",
        "        df = pd.read_csv(csv_file)\n",
        "\n",
        "        #오른쪽 눈가 이미지 처리\n",
        "        for folder in os.listdir(r_cheek_folder):\n",
        "            folder_path = os.path.join(r_cheek_folder, folder)\n",
        "            if os.path.isdir(folder_path):\n",
        "                for image_file in os.listdir(folder_path):\n",
        "                    if image_file.endswith('.jpg'):\n",
        "                        image_path = os.path.join(folder_path, image_file)\n",
        "                        image_id = image_file.split('_')[0] # _기준으로 앞의 값을 id로 지정\n",
        "                        label_data = df[df['ID'] == int((image_id))]['r_cheek_pigmentation'].values\n",
        "                        if len(label_data) > 0:\n",
        "                            label = label_data[0]\n",
        "                            self.image_paths.append(image_path)\n",
        "                            self.labels.append(label)\n",
        "\n",
        "        #왼쪽 눈가 이미지 처리\n",
        "        for folder in os.listdir(l_cheek_folder):\n",
        "            folder_path = os.path.join(l_cheek_folder, folder)\n",
        "            if os.path.isdir(folder_path):\n",
        "                for image_file in os.listdir(folder_path):\n",
        "                    if image_file.endswith('.jpg'):\n",
        "                        image_path = os.path.join(folder_path, image_file)\n",
        "                        image_id = image_file.split('_')[0] # _기준으로 앞의 값을 id로 지정\n",
        "                        label_data = df[df['ID'] == int((image_id))]['l_cheek_pigmentation'].values\n",
        "                        if len(label_data) > 0:\n",
        "                            label = label_data[0]\n",
        "                            self.image_paths.append(image_path)\n",
        "                            self.labels.append(label)\n",
        "\n",
        "        #넘파이 배열로 변경\n",
        "        self.image_paths = np.array(self.image_paths)\n",
        "        self.labels = np.array(self.labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "#train data 구성\n",
        "csv_file = \"/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/data/annotation/annotation_class2.csv\"\n",
        "r_cheek_folder = \"/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/data/image/Orientation/train/r_cheek\"\n",
        "l_cheek_folder = \"/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/data/image/Orientation/train/l_cheek\"\n",
        "\n",
        "#val data 구성\n",
        "val_csv_file = \"/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/data/annotation/annotation_class2.csv\"\n",
        "val_r_cheek_folder = \"/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/data/image/Orientation/val/r_cheek\"\n",
        "val_l_cheek_folder = \"/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/data/image/Orientation/val/l_cheek\"\n",
        "\n",
        "# 데이터 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 데이터셋 생성\n",
        "train_dataset = SkinDataset(csv_file=csv_file, r_cheek_folder=r_cheek_folder, l_cheek_folder=l_cheek_folder, transform=transform)\n",
        "val_dataset = SkinDataset(csv_file=csv_file, r_cheek_folder=val_r_cheek_folder, l_cheek_folder=val_l_cheek_folder, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=3)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True, num_workers=3)\n"
      ],
      "metadata": {
        "id": "UH3FhRl2GzPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropout_rate = 0.4085688567343784\n",
        "hidden_dim = 106\n",
        "weight_decay = 5.758813276927239e-05\n",
        "lr = 3.0207059901269228e-05\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "csEyUiMykNDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "class ResNetforClassification(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_rate= dropout_rate, hidden_dim=hidden_dim):\n",
        "        super(ResNetforClassification, self).__init__()\n",
        "        # Pretrained ResNet50 모델 로드\n",
        "        self.resnet50 = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "        # ResNet50의 마지막 fc 레이어의 입력 차원 자동으로 가져오기\n",
        "        num_ftrs = self.resnet50.fc.in_features\n",
        "        self.resnet50.fc = nn.Identity()  # Remove the classification head\n",
        "\n",
        "        self.fc1 = nn.Linear(num_ftrs, hidden_dim)  # 중간 차원으로 64 선택 (언제나 바꿀 수 있음)\n",
        "        self.dropout = nn.Dropout(p=0.4085688567343784)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)  # 최종 출력 차원은 클래스 수\n",
        "\n",
        "    def forward(self, image):\n",
        "        image_features = self.resnet50(image) # ResNet50을 통해 이미지 특징 추출\n",
        "        x = self.fc1(image_features)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)  # 드롭아웃 적용\n",
        "        x = self.fc2(x) # 최종 FC 레이어\n",
        "        return x\n",
        "\n",
        "# `device` 변수를 여기에 선언\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 클래스 가중치 정의\n",
        "class_weights = torch.tensor([0.9138, 0.4061], dtype=torch.float32).to(device)\n",
        "\n",
        "num_classes = 2\n",
        "model = ResNetforClassification(num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)  # 클래스 가중치 추가\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3.0207059901269228e-05, weight_decay=5.758813276927239e-05)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=20, eta_min=1e-6)\n",
        "\n",
        "###########################################################################################################################################################\\\n",
        "\n",
        "# 조기 종료 클래스\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "\n",
        "###########################################################################################################################################################\\\n",
        "\n",
        "# 모델 학습 및 검증\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50, patience=5):\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        corrects = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device).long()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            corrects += torch.sum(preds == labels.data)\n",
        "            total += labels.size(0)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = corrects.double() / total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        val_corrects = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device).long()\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_corrects += torch.sum(preds == labels.data)\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        val_loss = val_running_loss / len(val_loader.dataset)\n",
        "        val_acc = val_corrects.double() / val_total\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_acc:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}')\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict() , model_save_path)\n",
        "\n",
        "        early_stopping(val_loss)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "model_save_path = '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/지우님/orientation/orientation_pigmentation_cheek/model/model_v1/pigmentation_cheek_v2.pth'\n",
        "\n",
        "model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50, patience=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-C7WLU5j7U8",
        "outputId": "b0f3fd6c-fcf7-4921-b3cf-c3b118a857dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Loss: 0.5133, Train Accuracy: 0.7666, Val Loss: 0.3829, Val Accuracy: 0.8376\n",
            "Epoch [2/50], Train Loss: 0.2550, Train Accuracy: 0.8929, Val Loss: 0.3852, Val Accuracy: 0.8367\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch [3/50], Train Loss: 0.1270, Train Accuracy: 0.9519, Val Loss: 0.4864, Val Accuracy: 0.8299\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch [4/50], Train Loss: 0.0527, Train Accuracy: 0.9822, Val Loss: 0.6048, Val Accuracy: 0.8299\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch [5/50], Train Loss: 0.0248, Train Accuracy: 0.9928, Val Loss: 0.6502, Val Accuracy: 0.8367\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch [6/50], Train Loss: 0.0171, Train Accuracy: 0.9950, Val Loss: 0.7084, Val Accuracy: 0.8401\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 평가\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 평가를 위한 설정\n",
        "model_save_path =  '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/지우님/orientation/orientation_pigmentation_cheek/model/model_v1/pigmentation_cheek_v2.pth'\n",
        "\n",
        "# 모델 로드 및 평가\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 모델 불러오기\n",
        "model = ResNetforClassification(num_classes=2).to(device)\n",
        "model.load_state_dict(torch.load(model_save_path))\n",
        "model.eval()\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:  # val_loader로 변경\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        predicted_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "# 평가 지표 계산\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "\n",
        "# 혼동 행렬 그리기\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "W-WQjpdxklqW",
        "outputId": "84c30486-28a8-4840-8d9a-cd454951180a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8401\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.78      0.75       356\n",
            "           1       0.90      0.86      0.88       826\n",
            "\n",
            "    accuracy                           0.84      1182\n",
            "   macro avg       0.81      0.82      0.82      1182\n",
            "weighted avg       0.85      0.84      0.84      1182\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from torchvision.models import ResNet50_Weights\n",
        "\n",
        "#데이터 셋 클래스 정의 (오른쪽눈가, 왼쪽눈가 구분)\n",
        "class SkinDataset(Dataset):\n",
        "    def __init__(self, csv_file, r_cheek_folders, l_cheek_folders, transform=None):\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "\n",
        "        # csv 파일 로드\n",
        "        df = pd.read_csv(csv_file)\n",
        "\n",
        "        for r_folder in r_cheek_folders:\n",
        "            # 오른쪽 눈가 이미지 처리\n",
        "            for folder in os.listdir(r_folder):\n",
        "                folder_path = os.path.join(r_folder, folder)\n",
        "                if os.path.isdir(folder_path):\n",
        "                    for image_file in os.listdir(folder_path):\n",
        "                        if image_file.endswith('.jpg'):\n",
        "                            image_path = os.path.join(folder_path, image_file)\n",
        "                            image_id = image_file.split('_')[0]  # _기준으로 앞의 값을 id로 지정\n",
        "                            label_data = df[df['ID'] == int(image_id)]['r_cheek_pigmentation'].values\n",
        "                            if len(label_data) > 0:\n",
        "                                label = label_data[0]\n",
        "                                self.image_paths.append(image_path)\n",
        "                                self.labels.append(label)\n",
        "\n",
        "        for l_folder in l_cheek_folders:\n",
        "            # 왼쪽 눈가 이미지 처리\n",
        "            for folder in os.listdir(l_folder):\n",
        "                folder_path = os.path.join(l_folder, folder)\n",
        "                if os.path.isdir(folder_path):\n",
        "                    for image_file in os.listdir(folder_path):\n",
        "                        if image_file.endswith('.jpg'):\n",
        "                            image_path = os.path.join(folder_path, image_file)\n",
        "                            image_id = image_file.split('_')[0]  # _기준으로 앞의 값을 id로 지정\n",
        "                            label_data = df[df['ID'] == int(image_id)]['l_cheek_pigmentation'].values\n",
        "                            if len(label_data) > 0:\n",
        "                                label = label_data[0]\n",
        "                                self.image_paths.append(image_path)\n",
        "                                self.labels.append(label)\n",
        "\n",
        "        # 넘파이 배열로 변경\n",
        "        self.image_paths = np.array(self.image_paths)\n",
        "        self.labels = np.array(self.labels)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# 모델 정의\n",
        "class ResNetforClassification(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_rate= dropout_rate, hidden_dim=hidden_dim):\n",
        "        super(ResNetforClassification, self).__init__()\n",
        "        # Pretrained ResNet50 모델 로드\n",
        "        self.resnet50 = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "        # ResNet50의 마지막 fc 레이어의 입력 차원 자동으로 가져오기\n",
        "        num_ftrs = self.resnet50.fc.in_features\n",
        "        self.resnet50.fc = nn.Identity()  # Remove the classification head\n",
        "\n",
        "        self.fc1 = nn.Linear(num_ftrs, hidden_dim)  # 중간 차원으로 64 선택 (언제나 바꿀 수 있음)\n",
        "        self.dropout = nn.Dropout(p=0.4085688567343784)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)  # 최종 출력 차원은 클래스 수\n",
        "\n",
        "    def forward(self, image):\n",
        "        image_features = self.resnet50(image) # ResNet50을 통해 이미지 특징 추출\n",
        "        x = self.fc1(image_features)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)  # 드롭아웃 적용\n",
        "        x = self.fc2(x) # 최종 FC 레이어\n",
        "        return x\n",
        "\n",
        "# `device` 변수를 여기에 선언\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 클래스 가중치 정의\n",
        "class_weights = torch.tensor([0.9138, 0.4061], dtype=torch.float32).to(device)\n",
        "\n",
        "num_classes = 2\n",
        "model = ResNetforClassification(num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)  # 클래스 가중치 추가\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3.0207059901269228e-05, weight_decay=5.758813276927239e-05)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=20, eta_min=1e-6)\n",
        "\n",
        "csv_file = \"/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/data/annotation/annotation_class2.csv\"\n",
        "val_r_cheek_folder = [\"/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/data/image/Orientation/val/r_cheek/smart_pad\",\n",
        "                      \"/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/data/image/Orientation/val/r_cheek/r_cheek_origin\"]\n",
        "val_l_cheek_folder = [\"/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/data/image/Orientation/val/l_cheek/smart_pad\",\n",
        "                      \"/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/data/image/Orientation/val/l_cheek/l_cheek_origin\"]\n",
        "# 데이터 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_dataset = SkinDataset(csv_file=csv_file, r_cheek_folders=val_r_cheek_folder, l_cheek_folders=val_l_cheek_folder, transform=transform)\n",
        "\n"
      ],
      "metadata": {
        "id": "M583wKC1pBHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 평가\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# `device` 변수를 여기에 선언\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_save_path =  '/content/drive/MyDrive/Final_project_2조/02_2. 전처리 및 EDA_이미지/지우님/orientation/orientation_pigmentation_cheek/model/model_v1/pigmentation_cheek_v2.pth'\n",
        "\n",
        "# 모델 로드 및 평가\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 모델 불러오기\n",
        "model = ResNetforClassification(num_classes=2).to(device)\n",
        "model.load_state_dict(torch.load(model_save_path))\n",
        "model.eval()\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:  # val_loader로 변경\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        predicted_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "# 평가 지표 계산\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "\n",
        "# 혼동 행렬 그리기\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "id": "2Kzlnpa8Fowc",
        "outputId": "c84f4b7a-690d-4711-fcad-4eb13c476447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8401\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.78      0.75       356\n",
            "           1       0.90      0.86      0.88       826\n",
            "\n",
            "    accuracy                           0.84      1182\n",
            "   macro avg       0.81      0.82      0.82      1182\n",
            "weighted avg       0.85      0.84      0.84      1182\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WMod8pDeGKGF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}